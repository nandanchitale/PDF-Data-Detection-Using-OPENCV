{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4536,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "import openpyxl\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import os\n",
    "from icecream import ic\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference  : https://www.youtube.com/watch?v=oXlwWbU8l2o&t=1071s \n",
    "\n",
    "             https://www.youtube.com/watch?v=ADV-AjAXHdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PYTesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4537,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] = r\"C:\\Users\\nandan.chitale\\Documents\\Projects\\R&D\\PDF Data reader python\\Poppler\\Release-23.07.0-0\\poppler-23.07.0\\Library\\bin\"\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teserract Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --psm: Page Segmentation Mode (PSM) controls how Tesseract interprets the image. It specifies the layout analysis mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 0 = Orientation and script detection (OSD) only.\n",
    "###### 1 = Automatic page segmentation with OSD.\n",
    "###### 2 = Automatic page segmentation, but no OSD, or OCR. (not implemented)\n",
    "###### 3 = Fully automatic page segmentation, but no OSD. (Default)\n",
    "###### 4 = Assume a single column of text of variable sizes.\n",
    "###### 5 = Assume a single uniform block of vertically aligned text.\n",
    "###### 6 = Assume a single uniform block of text.\n",
    "###### 7 = Treat the image as a single text line.\n",
    "###### 8 = Treat the image as a single word.\n",
    "###### 9 = Treat the image as a single word in a circle.\n",
    "###### 10 = Treat the image as a single character.\n",
    "###### 11 = Sparse text. Find as much text as possible in no particular order.\n",
    "###### 12 = Sparse text with OSD.\n",
    "###### 13 = Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --oem: OCR Engine Mode (OEM) specifies the OCR engine to use.\n",
    "###### 0 = Original Tesseract only.\n",
    "###### 1 = Neural nets LSTM only.\n",
    "###### 2 = Tesseract + LSTM.\n",
    "###### 3 = Default, based on what is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --config: This parameter is used to specify additional Tesseract configuration variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveOriginalImg(img, index, output_path, write=True):\n",
    "    cv.imwrite(os.path.join(output_path, f\"{index}_original.png\"), img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraySacle Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayScaleImage(img, output_path, index, write=True):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_gray.png\"), gray)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blur Grayscaled Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blurImage(img, output_path, index, write=True):\n",
    "    blur = cv.GaussianBlur(img, (5,5), 0)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_blur.png\"), blur)\n",
    "    return blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert Grayscaled Image to read Lines accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thrasholdImage(img, output_path, index, write=True):\n",
    "    thresh = cv.threshold(img, 0,255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "    # thresh = cv.threshold(img, 127,255, cv.THRESH_BINARY)[1]\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_thresh.png\"), thresh)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invertImage(img, output_path, index, write=True):\n",
    "    invert = cv.bitwise_not(img)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_inverted.png\"), invert)\n",
    "    return invert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erode Vertical Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erodeVerticalLines(img, output_path, index, write=True):\n",
    "    hor = np.array([[1,1,1,1,1,1]])\n",
    "    vertial_lines_eroded_image = cv.erode(img, hor, iterations=10)\n",
    "    vertial_lines_eroded_image = cv.dilate(vertial_lines_eroded_image, hor, iterations=15)\n",
    "    \n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_verode.png\"), vertial_lines_eroded_image)\n",
    "    return vertial_lines_eroded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erode Horizontal Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erodeHorizontalLines(img, output_path, index, write=True):\n",
    "    ver = np.array([[1],[1],[1]])\n",
    "    horizontal_lines_eroded_image = cv.erode(img, ver, iterations=15)\n",
    "    horizontal_lines_eroded_image = cv.dilate(horizontal_lines_eroded_image, ver, iterations=15)\n",
    "    \n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_herode.png\"), horizontal_lines_eroded_image)\n",
    "    return horizontal_lines_eroded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Vertical and Horizontal Eroded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineErodedImages(vErodeImg, hErodeImg, output_path, index, write=True):\n",
    "    combinedImages = cv.add(vErodeImg, hErodeImg)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_eroded_combined.png\"), combinedImages)\n",
    "    return combinedImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialate Combined Images to make lines thicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialateImageToMakeLinesThicker(img, output_path, index, write=True):\n",
    "    kernal = cv.getStructuringElement(cv.MORPH_RECT, (2,2))\n",
    "    combineImageDialated = cv.dilate(img, kernal, iterations=1)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_combinedDialated.png\"), combineImageDialated)\n",
    "    return combineImageDialated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineRemovedNoiseLineImage(imgWithoutLineNoise, imgWithLinesEnhanced, output_path, index, write=True):\n",
    "    combinedImages = cv.add(imgWithoutLineNoise, imgWithLinesEnhanced)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_combineRemovedNoiseLineImage.png\"), combinedImages)\n",
    "    return combinedImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract combined and dilated image from original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtractCombinedDilatedFromOriginalImage(invertedImg, dilatedCombinedImg, output_path, index, write=True):\n",
    "    imgWithoutLines = cv.subtract(invertedImg, dilatedCombinedImg)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_imgWithoutLines.png\"), imgWithoutLines)\n",
    "    return imgWithoutLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove noise with erode and dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNoiseWithErodeAndDilate(img, output_path, index, write=True):\n",
    "    kernal = cv.getStructuringElement(cv.MORPH_RECT, (2,2))\n",
    "    imgWithoutLinesNoiseRemoved = cv.erode(img, kernal, iterations=1)\n",
    "    kernal = cv.getStructuringElement(cv.MORPH_RECT, (3,3))\n",
    "    imgWithoutLinesNoiseRemoved = cv.dilate(imgWithoutLinesNoiseRemoved, kernal, iterations=2)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_removeNoiseWithErodeAndDilate.png\"), imgWithoutLinesNoiseRemoved)\n",
    "    return imgWithoutLinesNoiseRemoved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilate Image\n",
    "(Pixels are added when structuring elements hits part of image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilateImage(thrasholdImg, output_path, index, write=True):\n",
    "    dilation_1_iterations = 12\n",
    "    dilation_2_iterations = 12\n",
    "    var_kernel_size_to_remove_gaps_between_words = (4,2)\n",
    "    var_simple_kernel_size = (1,5)\n",
    "    # kernel_to_remove_gaps_between_words = cv.getStructuringElement(cv.MORPH_TOPHAT, var_kernel_size_to_remove_gaps_between_words)\n",
    "    simple_kernel = np.ones(var_simple_kernel_size, np.uint8)\n",
    "    dilated_image_1 = cv.dilate(thrasholdImg, var_kernel_size_to_remove_gaps_between_words, iterations=dilation_1_iterations)\n",
    "    dilated_image = cv.dilate(dilated_image_1, simple_kernel, iterations=dilation_1_iterations)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_dilateImage1.png\"), dilated_image_1)\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_dilateImage2.png\"), dilated_image)\n",
    "        var_kernel_to_remove_gaps_between_words = f\"kernel_to_remove_gaps_between_words = cv.getStructuringElement(cv.MORPH_DILATE, {var_kernel_size_to_remove_gaps_between_words})\\n\"\n",
    "        var_simple_kernel = f\"simple_kernel = np.ones({var_simple_kernel_size}, np.uint8)\\n\"\n",
    "        var_dilation_1 = f\"kernel_to_remove_gaps_between_words : {dilation_1_iterations} Iterations\\n\"\n",
    "        var_dilation_2 = f\"simple_kernel : {dilation_2_iterations} Iterations\\n\"\n",
    "        with open(os.path.join(output_path, \"kernel.config\"), \"w+\") as file:\n",
    "            file.writelines(var_kernel_to_remove_gaps_between_words)\n",
    "            file.writelines(var_simple_kernel)\n",
    "            file.writelines(var_dilation_1)\n",
    "            file.writelines(var_dilation_2)\n",
    "    return dilated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find BLOB Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findContours(img, originalImg, output_path, index, write=True):\n",
    "    result = cv.findContours(img, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours = result[0]\n",
    "    \n",
    "    imgWithControusDrawn = originalImg.copy()\n",
    "    cv.drawContours(imgWithControusDrawn, contours, -1, (0, 255, 0), 1)\n",
    "    if write:\n",
    "        cv.imwrite(os.path.join(output_path, f\"{index}_imgWithControusDrawn.png\"), imgWithControusDrawn)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert contours to bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_contours_to_bounding_boxes(contours, original_Img, output_path, index, write=True):\n",
    "    bounding_boxes = []\n",
    "    image_with_all_bounding_boxes = original_Img.copy()\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, w, h))\n",
    "        # This line below is about\n",
    "        # drawing a rectangle on the image with the shape of\n",
    "        # the bounding box. Its not needed for the OCR.\n",
    "        # Its just added for debugging purposes.\n",
    "        image_with_all_bounding_boxes = cv.rectangle(image_with_all_bounding_boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "    if write:\n",
    "            cv.imwrite(os.path.join(output_path, f\"{index}_image_with_all_bounding_boxes.png\"), image_with_all_bounding_boxes)\n",
    "            \n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get mean height of bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_height_of_bounding_boxes(bounding_boxes):\n",
    "    heights = []\n",
    "    for bounding_box in bounding_boxes:\n",
    "        x, y, w, h = bounding_box\n",
    "        heights.append(h)\n",
    "    return np.mean(heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort_bounding_boxes_by_y_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_bounding_boxes_by_y_coordinate(bounding_boxes):\n",
    "    bounding_boxes = sorted(bounding_boxes, key=lambda x: x[1])\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Club bounding boxes by similar y co-ordinates into rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4555,
   "metadata": {},
   "outputs": [],
   "source": [
    "def club_all_bounding_boxes_by_similar_y_coordinates_into_rows(mean_height, bounding_boxes):\n",
    "    rows = []\n",
    "    half_of_mean_height = mean_height / 2\n",
    "    current_row = [ bounding_boxes[0] ]\n",
    "    for bounding_box in bounding_boxes[1:]:\n",
    "        current_bounding_box_y = bounding_box[1]\n",
    "        previous_bounding_box_y = current_row[-1][1]\n",
    "        distance_between_bounding_boxes = abs(current_bounding_box_y - previous_bounding_box_y)\n",
    "        if distance_between_bounding_boxes <= half_of_mean_height:\n",
    "            current_row.append(bounding_box)\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [ bounding_box ]\n",
    "    rows.append(current_row)\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort all rows by x co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4556,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_all_rows_by_x_coordinate(rows):\n",
    "    for row in rows:\n",
    "        row.sort(key=lambda x: x[0])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teserract Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4557,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseractConfig = r\"--dpi 72 --psm 6 --oem 3 tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to remove noise characters from string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to remove starting noise from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4558,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_noise(input_string):\n",
    "    try:\n",
    "        pattern = r'^[\\s|?/]+'\n",
    "        result = re.sub(pattern, '', input_string)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        ic(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serach Result from py teserractx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4559,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_from_tersseract(image_path):\n",
    "    # output = subprocess.getoutput('tesseract ' + image_path + ' - -l eng --oem 3 --psm 7 --dpi 72 -c tessedit_char_whitelist=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789().calmg* \"')\n",
    "    \n",
    "    # Convert text to boxes using teserract\n",
    "    # output = pytesseract.image_to_boxes(image_path, lang='eng', config=\"--psm 7 --dpi 72\")\n",
    "    \n",
    "    # Draw boxes around text generated by teserract\n",
    "    # img = cv.imread(os.path.join(image_path))\n",
    "    # height, width, _ = img.shape\n",
    "    # teserractImg = img.copy()\n",
    "        \n",
    "    output = pytesseract.image_to_string(image_path, config=tesseractConfig, output_type=Output.STRING)\n",
    "    # amount_boxes = len(data['text'])\n",
    "    # for i in range(amount_boxes):\n",
    "    #     if(float(data['conf'][i])) > 70:\n",
    "    #         (x,y,width,height) = (data['left'][i],data['top'][i],data['width'][i],data['height'][i])\n",
    "    #         cv.rectangle(teserractImg, (x,y), (x+width, y+height), (0,255,0), 2)\n",
    "                \n",
    "    # cv.imwrite(os.path.join(output_path, f\"teserractImg.png\"), teserractImg)\n",
    "    output = output.strip()\n",
    "    output = remove_prefix_noise(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting text from box using OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_each_bounding_box_and_ocr(rows, original_image, image_slice_path):\n",
    "    table = []\n",
    "    current_row = []\n",
    "    image_number = 0\n",
    "    for row in rows:\n",
    "        for bounding_box in row:\n",
    "            x, y, w, h = bounding_box\n",
    "            y = y - 5\n",
    "            cropped_image = original_image[y:y+h, x:x+w]\n",
    "            sliced_img_path = os.path.join(image_slice_path, f\"{str(image_number)}.jpg\")\n",
    "            cv.imwrite(sliced_img_path, cropped_image)\n",
    "            results_from_ocr = get_result_from_tersseract(sliced_img_path)\n",
    "            current_row.append(results_from_ocr)\n",
    "            image_number += 1\n",
    "        table.append(current_row)\n",
    "        current_row = []\n",
    "        \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_excel_file(table, output_path, outputFileName = \"output.xlsx\")->bool:\n",
    "    returnValue = False\n",
    "    try:\n",
    "        filePath = os.path.join(output_path, outputFileName)\n",
    "        # Check file exists. if not,create one\n",
    "        if not os.path.exists(filePath):\n",
    "            # Create a new workbook\n",
    "            workbook = Workbook()\n",
    "        else:\n",
    "            # Load workbook\n",
    "            workbook = openpyxl.load_workbook(filePath)\n",
    "            \n",
    "        # Select active sheet\n",
    "        worksheet = workbook.active\n",
    "        \n",
    "        # Append data\n",
    "        for row in table:\n",
    "            worksheet.append(row)\n",
    "            \n",
    "        # Save data\n",
    "        workbook.save(filePath)\n",
    "    except FileNotFoundError:\n",
    "        workbook = openpyxl.Workbook()\n",
    "    except Exception as e:\n",
    "        ic(e)\n",
    "    \n",
    "    return returnValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw Bounding Boxes around text in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoundingBoxesAroundTextInImage(img, output_path):\n",
    "    \"\"\"\n",
    "        This method is used to transform input image\n",
    "        Which will be used for text detection using pytteserract\n",
    "        Steps : \n",
    "            1> Input Image\n",
    "            2> Grayscale\n",
    "            3> Thrashhold (INVERT)\n",
    "            4> Vertial lines erode\n",
    "            5> Horizontal lines Erode\n",
    "            6> Combine Vertial and horizontal lines erode\n",
    "            7> Dilate Combined eroded lines image\n",
    "            8> Combine thrashold with dilated lines image\n",
    "            9> Remove lines from thrashold (8-3)\n",
    "            10> Remove noise from image using erode and dilate\n",
    "            11> Redilate noise reduced image\n",
    "            12> Draw contoures around text\n",
    "            13> Convert contours to bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        img (Image(opencv)): Opencv image object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Save Original Image\n",
    "        originalImg = saveOriginalImg(img, 1, output_path)\n",
    "        \n",
    "        # Grayscale image\n",
    "        img = grayScaleImage(img, output_path, index=2)\n",
    "\n",
    "        # Thrashold Image\n",
    "        thrasholdImg = thrasholdImage(img, output_path, index=3)\n",
    "\n",
    "        # Invert image\n",
    "        # invertedImg = invertImage(thrasholdImage, output_path,index=4)\n",
    "\n",
    "        # Erode vertical lines\n",
    "        vErodeImg = erodeVerticalLines(thrasholdImg, output_path, index=5)\n",
    "\n",
    "        # Erode Horizontal lines\n",
    "        hErodeImg = erodeHorizontalLines(thrasholdImg, output_path, index=6)\n",
    "\n",
    "        # Combine Eroded Images\n",
    "        combinedErodedImage = combineErodedImages(vErodeImg, hErodeImg, output_path, index=7)\n",
    "\n",
    "        # Dilate Combined Image to make lines thicker\n",
    "        linesDialatedImage = dialateImageToMakeLinesThicker(combinedErodedImage, output_path, index=8)\n",
    "\n",
    "        # Remove the lines\n",
    "        imgWithoutLines = subtractCombinedDilatedFromOriginalImage(thrasholdImg , linesDialatedImage, output_path, index=9)\n",
    "\n",
    "        # Remove Noise with Erode and Dilate\n",
    "        noiseRemovedImg = removeNoiseWithErodeAndDilate(imgWithoutLines, output_path, index=10)\n",
    "\n",
    "        # Combine Removed noise image with lines image\n",
    "        # img = combineRemovedNoiseLineImage(noiseRemovedImg, linesDialatedImage, output_path, index=11)\n",
    "\n",
    "        # Dilate Image\n",
    "        dilatedImage = dilateImage(noiseRemovedImg, output_path, index=12)\n",
    "\n",
    "        # Contours\n",
    "        contours = findContours(dilatedImage, originalImg, output_path, index=13)\n",
    "\n",
    "        # Convert contours to boxes\n",
    "        boundingBoxes = convert_contours_to_bounding_boxes(contours, originalImg, output_path, index=14)\n",
    "        \n",
    "        return boundingBoxes, noiseRemovedImg\n",
    "    except Exception as e:\n",
    "        ic(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract text from bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4563,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTextUsingBoundingBoxes(boundingBoxes, img, image_slice_path):\n",
    "    \"\"\" Method to get text from images with bounding boxes\n",
    "        This method will create sub images for each bounding box\n",
    "        Then will use pyttesseract to get the text from sub image\n",
    "        And finally, will convert that data to excel sheet.\n",
    "    Args:\n",
    "        boundingBoxes (dict): Bounding boxes around text in image\n",
    "        img (OPENCV image object): Original Image to draw bounding boxes on.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get mean height of boxes\n",
    "        meanHeight = get_mean_height_of_bounding_boxes(boundingBoxes)\n",
    "\n",
    "        # Sort bounding boxes\n",
    "        boundingBoxes = sort_bounding_boxes_by_y_coordinate(boundingBoxes)\n",
    "\n",
    "        # Club all bounding boxes by similar y co-ordinates\n",
    "        rows = club_all_bounding_boxes_by_similar_y_coordinates_into_rows(meanHeight, boundingBoxes)\n",
    "\n",
    "        # Sort rows by x co-ordinate\n",
    "        rows = sort_all_rows_by_x_coordinate(rows)\n",
    "\n",
    "        # Crop each box and extract text using ocr\n",
    "        table = crop_each_bounding_box_and_ocr(rows, img, image_slice_path)\n",
    "        \n",
    "        return table\n",
    "    except Exception as e:\n",
    "        ic(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pdf page to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf2ImageConverter(pdf_file_path, image_file_path)->bool:\n",
    "    \"\"\"Method to convert pdf pages to images\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (string): PDF File path\n",
    "        image_file_path (string): Output Image file path\n",
    "\n",
    "    Returns:\n",
    "        bool: True/False on success/failure\n",
    "    \"\"\"\n",
    "    returnValue = False\n",
    "    try:\n",
    "        images = convert_from_path(pdf_file_path, dpi=300)\n",
    "        if len(images) > 0:\n",
    "            for i, image in enumerate(images):\n",
    "                image_path = f\"{image_file_path}/page_{i+1}.png\"\n",
    "                image.save(image_path, \"png\")\n",
    "\n",
    "            returnValue = True\n",
    "    except Exception as e:\n",
    "        ic(e)\n",
    "        \n",
    "    return returnValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Code\n",
    "### Steps : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "1> Load pdf file.\n",
    "2> Convert pdf file pages to image.\n",
    "3> Extract text data from each image \n",
    "4> Append text data to Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4565,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = f\"{datetime.today().strftime('%d_%b_%Y_%H_%M')}\"\n",
    "\n",
    "# This path is used to store all data \n",
    "img_path = os.path.join(\"pdf2Images\",current_timestamp)\n",
    "if not os.path.exists(img_path):\n",
    "    os.mkdir(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdffilename = 'PO_63_12042023.pdf'\n",
    "# pdffilename = 'IPCA-PARVATI-01.04.21.pdf'\n",
    "pdf_file_path = os.path.join('TestFiles')\n",
    "# pdf_file_path = os.path.join('TestFiles', pdffilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Data from Each Image and Append it to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to image conversion succeessfull at pdf2Images\\09_Aug_2023_16_53\\Chandan1.pdf\\pdf2ImgData\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to image conversion succeessfull at pdf2Images\\09_Aug_2023_16_53\\Chandan2.pdf\\pdf2ImgData\n",
      "File to image conversion succeessfull at pdf2Images\\09_Aug_2023_16_53\\Kundan1.pdf\\pdf2ImgData\n",
      "File to image conversion succeessfull at pdf2Images\\09_Aug_2023_16_53\\Senior1.pdf\\pdf2ImgData\n",
      "File to image conversion succeessfull at pdf2Images\\09_Aug_2023_16_53\\Shriram1.pdf\\pdf2ImgData\n",
      "File to image conversion succeessfull at pdf2Images\\09_Aug_2023_16_53\\Shriram2.pdf\\pdf2ImgData\n",
      "File to image conversion succeessfull at pdf2Images\\09_Aug_2023_16_53\\Shriram3.pdf\\pdf2ImgData\n"
     ]
    }
   ],
   "source": [
    "# Iterate on images converted from pdf\n",
    "inputPdfFileDirs = 'TestFiles'\n",
    "pdfFiles = [file for file in os.listdir(inputPdfFileDirs)]\n",
    "\n",
    "for file in pdfFiles:\n",
    "    pdfDataPath = os.path.join(img_path, file)\n",
    "    pdfFile = os.path.join(inputPdfFileDirs, file)\n",
    "    if not os.path.exists(pdfDataPath):\n",
    "        os.makedirs(pdfDataPath)\n",
    "        \n",
    "    # Setup paths\n",
    "    # Images converted from pdf pages\n",
    "    pdf2ImageDataPath = os.path.join(pdfDataPath, \"pdf2ImgData\")\n",
    "    if not os.path.exists(pdf2ImageDataPath):\n",
    "        os.mkdir(pdf2ImageDataPath)\n",
    "        \n",
    "    # Tmp dir where image processing will be stored\n",
    "    tmp_img_path = os.path.join(pdfDataPath, \"tmp\")\n",
    "    if not os.path.exists(tmp_img_path):\n",
    "        os.mkdir(tmp_img_path)\n",
    "    \n",
    "    # Output files path\n",
    "    output_path = os.path.join(pdfDataPath, \"output\")\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)    \n",
    "    \n",
    "    # Convert pdf file to image\n",
    "    pdf2ImageConvesion = pdf2ImageConverter(pdfFile, pdf2ImageDataPath)\n",
    "    print(f\"File to image conversion {'succeessfull' if pdf2ImageConvesion else 'failed'} at {pdf2ImageDataPath}\")\n",
    "        \n",
    "    imageFiles = [file for file in os.listdir(pdf2ImageDataPath)]\n",
    "\n",
    "    for i, file in enumerate(imageFiles):\n",
    "        save_tmp_img_path = os.path.join(tmp_img_path, str(i+1))\n",
    "        if not os.path.exists(save_tmp_img_path):\n",
    "            os.mkdir(save_tmp_img_path)\n",
    "            \n",
    "        image_slice_path = os.path.join(save_tmp_img_path, \"image_slices\")\n",
    "        if not os.path.exists(image_slice_path):\n",
    "            os.mkdir(image_slice_path)\n",
    "            \n",
    "        # Read File using opencv\n",
    "        img = cv.imread(os.path.join(pdf2ImageDataPath, file))\n",
    "        \n",
    "        # Get Bounds on image\n",
    "        bounds, img = getBoundingBoxesAroundTextInImage(img, save_tmp_img_path)\n",
    "        \n",
    "        # Get Text from bounding boxes\n",
    "        textData = extractTextUsingBoundingBoxes(bounds, img, image_slice_path)\n",
    "        \n",
    "        if textData is not None:\n",
    "            # Append Data to excel   \n",
    "            generate_excel_file(textData, output_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
